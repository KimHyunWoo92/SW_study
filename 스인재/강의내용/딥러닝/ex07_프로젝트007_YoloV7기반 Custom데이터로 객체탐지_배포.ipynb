{"cells":[{"cell_type":"markdown","metadata":{"id":"mB2LsNfN4MbV"},"source":["<table border=1 width=100%>\n","    <tr><td style=\"border: 1px solid black; width:600px; height:30px; text-align: center;\"><font size=4 color=blue><b>[프로젝트] 학습목표</b></font></td></tr>       \n","    <tr><td style=\"border: 1px solid black; text-align: left;\"><font size=3>\n","○ 객체 탐지 방법에 대해 학습한다.<br><br>\n","○ yolo 기반 라이브러리를 활용한 객체 탐지 방법에 대해 학습한다.<br><br>\n","○ yolov7을 활용하여 커스텀 데이터의 객체 탐지 방법에 대해 학습한다.\n","</font></td></tr>   \n","</table>"]},{"cell_type":"markdown","metadata":{"id":"j6qaskbn4MbW"},"source":["# 객체 탐지\n","\n","## 개요\n","\n","- 참고 : https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch1-Object-Detection.html\n","\n","\n","- 객체 탐지(object detection) : 컴퓨터 비전과 이미지 처리와 관련된 컴퓨터 기술로서, 디지털 이미지와 비디오에서 관심 객체(예: 인간, 건물, 자동차 등)의 위치를 감지하는 작업\n","  - 활용 분야 : 얼굴 검출, 보행자 검출, 영상 복구, 비디오 감시, 자율주행 등\n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_object_detect.PNG\" width=30%> </center>\n","  \n","- 객체 분류 : 탐지된 객체가 무엇인지 판단하고 분류하는 작업\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_object_detect2.png\" width=30%> </center>\n","\n","- 객체 탐지 및 분류 알고리즘 (참고 : 위키백과)\n","  - 머신러닝 기반 접근 : 아래 알고리즘을 사용하여 정의하고 SVM 등을 이용하여 분류\n","    - Haar features 기반 비올라–존스 객체탐지 프레임워크\n","    - Scale-invariant feature transform (SIFT)\n","    - Histogram of oriented gradients (HOG) 기능\n","  - 딥러닝 기반 접근 : 구체적 정의가 필요 없고, 일반적으로 합성곱 신경망(CNN)을 활용\n","    - Region Proposals (R-CNN, Fast R-CNN, Faster R-CNN, cascade R-CNN)\n","    - Single Shot MultiBox Detector (SSD)\n","    - You Only Look Once (YOLO)\n","    - Single-Shot Refinement Neural Network for Object Detection (RefineDet)\n","    - Retina-Net\n","    - Deformable convolutional networks\n","    \n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_object_detect3.png\" width=60%> </center>\n","<center><font size=1>참고 : Zou et al. 2019. Object Detection in 20 Years: A Survey</font></center>    \n","\n","\n","- Two-Stage Detector\n","  - Classification, Regional Proposal을 순차적으로 수행하여 결과를 얻는 방법\n","  - 객체를 검출하는 정확도 측면에서는 좋은 성능을 냈지만, 예측 속도가 느려 실시간 탐지에 제한\n","  - R-CNN, Fast R-CNN, Faster R-CNN 등\n","\n","- One-Stage Detector :\n","  - Classification, Regional Proposal을 동시에 수행하여 결과를 얻는 방법    \n","  - Two-Stage Detector의 속도 문제를 해결하기 위해 제안\n","  - YOLO, SSD, RetinaNet 등\n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_object_detect4.png\" width=60%> </center>\n","<center><font size=1>참고 : Naver BoostCamp AI Tech - edwith 강의</font></center>  "]},{"cell_type":"markdown","metadata":{"id":"p7hQLv1L4MbW"},"source":["## 바운딩 박스 (Bounding Box)\n","\n","- 객체 탐지 모델에서 바운딩 박스는 타겟 위치를 특정하기 위해 사용\n","  - 타겟 위치를 X와 Y축을 이용하여 사각형으로 표현\n","  - 예를 들어, 바운딩 박스 값은 (X 최소값, Y 최소값, X 최대값, Y 최대값)으로 표현\n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_bounding_box.PNG\" width=40%> </center>\n","<center><font size=1>참고 : https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection</font></center>\n","  \n","\n","- 일반적으로 효율성을 높이기 위해 바운딩 박스의 위치를 0-1값으로 정규화\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_bounding_box1.PNG\" width=40%> </center>\n","<center><font size=1>참고 : https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/raw/master/img/bc2.PNG</font></center>\n","\n","- 객체 탐지 모델에 사용되는 데이터의 크기가 크기 때문에 바운딩 박스를 사용하여 객체의 위치를 설정하여 탐지하고 딥러닝 과정에서 바운딩 박스 영역만 활용"]},{"cell_type":"markdown","metadata":{"id":"TXohTEC2vSAc"},"source":["# 객체탐지의 사례 및 활용\n","\n","- 주 활용사례 : 문서스캔, 비디오 감시, 의료영상, 교통 흐름 감지 등\n","\n","- 무인점포의 매장 및 재고 관리, 고객인식, 상품인식, 동작인식 등의 사례\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_example1.png\" width=40%><br><font size=1>자료:ITWorld Korea</font> </center><br>\n","\n","- 자동차 인식, 교통표지판 인식, 차선인식, 도로인식, 차간 거리 인식 등\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_example1.png\" width=40%><br><font size=2>자료:ITWorld Korea</font> </center>\n","\n","- 스마트 공장의 활용\n","  - 자재 이동 추적, 제품 및 포장의 결함 식별, 폐기물 감축\n","  - 승인되지 않은 직원 행동을 모니터링하여 프로토콜 시행\n","  - 문서 처리 간소화, 재고 최적화, 보험금 청구 지원, 효율적인 물류 관리 지원\n","\n","- 스마트 그리드의 활용 : 변전소, 전력망, 유틸리티의 결함 및 이상징후 (고장, 화재 등) 모니터링\n","\n","\n","- 두뇌-컴퓨터 인터페이스 (BCI)\n","  - 가시성이 낮거나 극한의 온도 또는 카메라 사용이 제한되는 위험한 상황에서 활용 (건설, 정유공장 작업, 위험한 현장 작업에서 양손을 사용하여 기계를 검사하거나 조작하는 경우)\n","  - 카메라 대신 뇌전도(EOG)와 같은 뇌 및 생체신호를 해석하여 눈의 움직임을 모니터링\n"]},{"cell_type":"markdown","metadata":{"id":"c04WFept4MbX"},"source":["## Yolo (You only Look Once : 한 번보고 처리한다)\n","\n","- 참고\n","  - https://blog.nerdfactory.ai/2021/05/06/You-Only-Look-Once.-YOLO.html\n","  - https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p\n","  - 전체 Yolo 버전별 테스트 코드\n","    - https://github.com/roboflow/notebooks/tree/main/notebooks\n","\n","- 대표적인 객체 탐지 모델\n","- 하나의 컨볼루션 네트워크를 통해 대상의 위치(바운딩박스)와 클래스(분류)를 한번에 예측 (1 state dectection 알고리즘)\n","  \n","  - 이미지를 S x S 그리드로 분할 (초기 논문 S = 7)\n","  - 이미지 전체를 신경망에 넣고 특징 추출을 통해 예측 텐서(그리드별 바운딩박스 정보, 신뢰점수, 분류 클래스 확률)를 생성\n","  - 그리드별 예측 정보를 기반으로 바운딩박스 조정 및 분류 작업 수행\n","  - 각 그리드 셀은 B 개의 바운딩박스와 바운딩박스에대한 신뢰점수를 가짐\n","  - 각 그리드 셀은 C 개의 분류 클래스 확률을 가짐\n","  - 각 바운딩박스는 왼쪽상단 좌표 (x, y)와 폭과 높이 (w, h), 신뢰점수를 가짐\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo01.png\" width=50%> </center>\n","\n","- 현재 YoloV8까지 공개\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo2.png\" width=60%> </center>"]},{"cell_type":"markdown","metadata":{"id":"jZwin4rZ4MbX"},"source":["### YoloV1\n","- Josept Redmon이 2015년에 yolov1 논문을 발표하고 공개\n","- convolutional layer로 이미지로부터 특징을 추출하고, FC layer로 바운딩박스와 class 확률을 예측\n","- 24개의 convolutional layer와 2개의 fully connected layer로 구성\n","- GoogLeNet에서 영향을 받아 1x1 차원 감소 layer (Inception) 뒤에 3x3 convolutional layer를 이용\n","\n","\n","- Image → CNN → FC → PT(Prediction Tensor) 순서로 동작\n","\n","\n","- 네트워크 구조\n","  - VGG16 모델을 기반으로 224x224 크기의 해상도로 학습을 하고, 448x448 크기의 이미지에 대해서 Object Detection을 수행하도록 설계\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo03.png\" width=50%> </center>\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo03_02.png\" width=50%> </center>\n","\n","- 단점\n","  - 여러 물체들이 겹쳐있으면 제대로 된 예측이 어려움\n","  - 물체가 작을 수록 정확도가 감소\n","  - 바운딩박스 형태가 data를 통해 학습되므로 새로운 형태의 바운딩박스의 경우 정확히 예측하지 못함   "]},{"cell_type":"markdown","metadata":{"id":"eEluNXjO4MbX"},"source":["### YoloV2\n","\n","- YOLOv1 모델의 문제점을 보완하여 정확도를 높인 모델\n","- 특징\n","  - CNN에 Batch Normalization 적용 - 2% 향상\n","  - 학습 전 이미지 분류 모델을 큰 해상도의 이미지에 대해 fine-tuning 단계를 거쳐 고해상도 이미지로 CNN 신경망을 학습 - 4% 향상\n","  - Anchor Box의 개념 도입\n","    - 마지막 단의 Fully Connected layer을 떼어내고 Convolutional Network 형태로 prediction을 계산\n","    - 바운딩 박스의 좌표를 예측하기 보다는 사전에 정의한 앵커 박스에서 offset을 예측\n","    - Anchor Box의 핵심 : 사전에 크기와 비율이 모두 결정되어 있는 박스를 전제로, 학습을 통해서 이 박스의 위치나 크기를 세부 조정하는 것\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo04.png\" width=40%> </center>\n","\n","  - features map 크기를 7x7 에서 13x13으로 변경\n","  \n","  - Multi-Scale Training : 작은 물체도 추출하기 위해 여러 스케일의 이미지를 학습 (일정반복마다 입력이미지의 해상도를 변경)\n","  \n","- 네트워크 구조\n","  - Darknet 19 신경망을 구축하여 이용\n","  - VGG-16 신경망에서 대부분의 가중치가 쓰인 FC layer를 제거하여 가중치 파라미터 수를 낮춰줬기 때문에 속도가 향상\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo05.png\" width=60%> </center>"]},{"cell_type":"markdown","metadata":{"id":"7qMuVTQU4MbY"},"source":["### YoloV3\n","\n","- Josept Redmon이 2018년 4월 제안\n","\n","- shortcut connection이 추가되어 53개의 layer를 가지는 Darknet-53을 backbone network로 사용\n","- Darkenet-53은 ResNet-101보다 1.5배 빠르며, ResNet-152와 비슷한 성능을 보이지만 2배 이상 빠름\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo06.png\" width=70%> </center>\n","\n","- 일반적인 SSD와 같은 구조는, feature extractwor의 앞쪽에서 나온 feature map은 표현력이 부족\n","- 이를 보완하기 위해 우측처럼 다시 deconvolution으로 feature map의 크기를 확장시켜 high-level feature를 뽑도록 함\n","- 왼쪽과 오른쪽의 feature map을 concat해서(왼쪽에서 위치정보 등을 갖고오는 식으로) 표현력을 향상시켜 사용함\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo07.png\" width=70%> </center>"]},{"cell_type":"markdown","metadata":{"id":"bYPBOUlC4MbY"},"source":["### YoloV4\n","\n","- AlexeyBochkousky에 의해 2020년 4월 발표\n","- YoloV3에 비해 AP, FPS가 각각 10%, 12% 증가\n","- CSPNet 기반의 backbone(CSPDarkNet53)을 설계하여 사용\n","- 다양한 기법을 적용항 성능 향상 : WRC (Weighted-Residual-Connections), CSP (Cross-Stage-Partial-Connections), CmBN (Cross mini-Batch Normalizations), SAT (Self-Adversarial-Training), Mish Activation, Mosaic Data Agumentation, Drop Block Regularization, CIOU Loss\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo08.png\" width=50%> </center>\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo09.png\" width=50%> </center>"]},{"cell_type":"markdown","metadata":{"id":"dZmOQURV4MbY"},"source":["### YoloV5\n","\n","\n","- GlennJocher에 의해 2020년 6월 발표\n","- YoloV4에 비해 낮은 용량과 빠른 속도, 성능은 비슷 (FPS : 140, mAP : 89.5)\n","- YoloV4와 같은 CSPNet 기반의 backbone을 설계하여 사용\n","- Darknet이 아닌 PyTorch 구현이기 때문에, 이전 버전들과 다름\n","\n","- 다른 yolo 모델들과 달리 크기별로 구분 : Yolov5s, Yolov5m, YOlov5l, Yolov5x 등/\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo10.png\" width=40%> </center>"]},{"cell_type":"markdown","metadata":{"id":"CuK4OzgU4MbZ"},"source":["### YoloV7\n","\n","- Chien-Yao Wang에 의해 2022년 7월 발표\n","- E-ELAN 네트워크를 사용\n","\n","- YOLO 제품군의 새로운 물체 탐지기로 현재까지 가장 빠르고 정확한 실시간 물체 탐지기\n","  \n","- 달라진 점\n","  - 아키텍처 개선\n","  - 훈련가능한 BoF (Bag of Freebies)\n","  - 인간 포즈 추정 모델을 포함하는 첫번째 YOLO 모델  \n","  \n","  - bag-of-freebies 방법을 사용한 성능 향상\n","     - model reparameterization : 훈련시 여러 개의 레이어 (Conv, BN)들을 학습하고 추론 시에는 해당 레이어들을 하나의 레이어로 합침 (RepVGG를 수정한 형태)\n","     - Label assignment : 모델의 에측, ground truth (예측되기를 원하는 라벨)의 분포를 고려해서 새로운 soft label를 만듬 (ATSS, OTA, SimOTA 방법)\n","\n","  - 파라미터와 계산을 고려한 model scaling 방법 사용\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo11.png\" width=70%> </center>"]},{"cell_type":"markdown","metadata":{"id":"sE3NsRz5K1mk"},"source":["### YoloV6\n","\n","- 2022년 9월 발표된 버전\n","- 여러 방법을 이용하여 알고리즘의 효율을 높이고, 특히 시스템에 탑재하기 위한 Quantization과 distillation 방식도 일부 도입하여 성능 향상\n","\n","- 백본은 EfficientRep Backbone이 사용\n","  - Neck 부분은 Rep-PAN이 사용\n","  - head는 Efficient decoupled head가 사용\n","\n","- CSPstackRep Block = CSP(cross stage partial) + RepVGG 방식이 backbone에 사용\n","\n","- 소형 모델은 일반 단일 경로 백본을 특징으로 하고 대형 모델은 효율적인 다중 분기 블록을 기반으로 구축\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo12.png\" width=70%> </center>"]},{"cell_type":"markdown","metadata":{"id":"sNnYkIkHK6gF"},"source":["### YoloV8\n","\n","- 2023년 1월 발표된 버전\n","- YOLO 모델을 위한 완전히 새로운 리포지토리를 출시하여 개체 감지\n","- 인스턴스 세분화 및 이미지 분류 모델을 train하기 위한 통합 프레임워크로 구축됨\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolo13.png\" width=70%> </center>"]},{"cell_type":"markdown","metadata":{"id":"LFcYr7mooyop"},"source":["### Data annotation 기법 <font size=2>(참고 : https://blog.naver.com/datahive/222224206050)</font>\n","\n","- 메타데이터를 데이터 셋에 추가하는 작업\n","  - 인공지능이  데이터의 내용을 이해할 수 있도록 주석을 달아주는 작업\n","  \n","- bounding box : 이미지 혹은 영상 안 객체의 가장자리에 딱 맞춘 사각형 틀을 그려주는 것\n","  - 자율주행 차량이 실제 시나리오에서 주변 환경과 모든 물체를 인식하고 이해하도록 훈련하는데 활용\n","  - 장점 : 쉽고 빠르게 데이터를 가공\n","  - 단점 : 객체의 유형과 위치에 따라 바운딩 박스 안에 해당 객체에 속하지 않는 픽셀이 포함될 수 있음\n","  - 난이도 : ★★\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/106_bounding_box.png\" width=50%> </center>  \n"]},{"cell_type":"markdown","metadata":{"id":"NabkFd7MsCNA"},"source":["- polygon : 길 위에 있는 보행자나 자전거같이 규칙적이지 않은 형태의 객체이 경계면을 여러개의 특징점으로 영역을 지정\n","  - 훨씬 정확하게 객체에 속한 픽셀을 어노테이션 할 수 있는 기법\n","  - 작업 속도가 약간 느림\n","  - 장점 : 객체의 윤곽을 정밀하게 선택할 수 있어, 인공지능에게 그 물체의 크기와 형태를 정확하게 인식시킬 수 있음\n","  - 단점 : 겹쳐져 있는 객체에 폴리곤 기법을 적용하는 경우엔 목표물을 정확히 인식하기 어려움\n","  - 난이도 : ★★\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/106_polygon.png\" width=50%> </center>    "]},{"cell_type":"markdown","metadata":{"id":"j0IPr6_JsMPi"},"source":["- polyline : 객체 테두리에 여러 점을 찍어 선으로 구성되어 나타내는 기법\n","  - 동일한 장소에서 시작하고 종료할 필요가 없는 형태를 추적해야 할 때 유용\n","  - 자율 주행 자동차의 차선 탐지 훈련, 물류창고의 컨베이어 벨트 탐지 훈련 등에 활용\n","  - 장점 : 전선 감지, 차선 감지 등 직선 혹은 곡선을 추적해야 하는 사례에 매우 유용\n","  - 단점 : 이미지 상 객체의 선이 1픽셀 너비에 가까운 경우에만 작동하기 때문에 객체의 선 너비가 넓은 경우엔 폴리곤 기법으로 대체\n","  - 난이도 : ★★\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/106_polyline.PNG\" width=50%> </center>      "]},{"cell_type":"markdown","metadata":{"id":"NsE-cx8ZsMWr"},"source":["- point : 이미지 속 객체의 개수를 계산하거나 군중 속에 있는 사람을 선택하는 등 이미지 상 단일 픽셀을 찾아내는 경우에 매우 유용\n","  - 장점 : 작업 방법이 매우 쉽고 간단하며 그림판 같은 매우 간단한 툴을 이용 가능\n","  - 단점 : 객체의 윤곽이 명확하지 않은 이미지에는 적용하기 어려움\n","  - 난이도 : ★★\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/106_point.PNG\" width=50%> </center>    "]},{"cell_type":"markdown","metadata":{"id":"KMaJoyScsMkR"},"source":["- cuboid : 바운딩 박스와 굉장히 비슷한 방식의 기법으로 3D 형태\n","  - 길이, 너비뿐만 아니라 폭까지 표시할 수 있어 2D 이미지만으로는 부족한 정밀도를 높일 수 있음\n","  - 산업로봇과 같은 기계가 물체를 더욱 정확하게 인식할 수 있게 하는 경우에 흔히 사용\n","  - 장점 : 객체의 깊이에 대한 정보가 제공되기 때문에 3D 환경에서 중요한 정보들을 식별\n","  - 단점 : 객체가 불규칙한 형태를 가지거나 가려진 부분이 있는 경우, 잘린 부분이 있는 경우엔 작업이 어려움\n","  - 난이도 : ★★★★\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/106_cuboid.PNG\" width=50%> </center>    "]},{"cell_type":"markdown","metadata":{"id":"qMGLSDhFuN_s"},"source":["- semantic segmentation : 이미지에 있는 모든 픽셀을 채색하고 해당하는 클래스로 분류하는 방식\n","  - 자율 주행 자동차, 의료 영상 분석, 산업 검사, 위성 영상, 로봇 비전 등에 유용하게 활용\n","  - 이미지 속 모든 장면과 상황을 인식할 수 있게 가공하는 고차원의 방법\n","  - 장점 : 기계가 해당 장면을 완벽히 이해시킬 수 있음\n","  - 단점 : 이미지의 모든 픽셀을 해당하는 클래스로 분류해야 하기 때문에 많은 작업이 필요\n","  - 난이도 : ★★★★\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/106_segmentation.PNG\" width=30%> </center>    "]},{"cell_type":"markdown","metadata":{"id":"rk-UY5cK4Mbd"},"source":["\\# labelimg를 이용하여 customized 데이터셋 만들기"]},{"cell_type":"markdown","metadata":{"id":"AUYq7nAo4Mbe"},"source":["- 라벨링할 이미지를 원하는 폴더에 저장한다 (./images/yoloimg)\n","\n","- 라벨링 툴을 이용하여 이미지에 포함된 개체를 라벨링\n","  - LabelImg, LabelMe, Label Studio, Diffgram, ImageTagger, VIA, Make Sense, COCO Annotator, DataTurks 등\n","  - roboflow : 라벨링툴 및 데이터셋 제공\n","    - https://public.roboflow.com/object-detection\n","  - CVAT : 크롬에서 실행, 강력한 최신 기능 지원\n","    - https://github.com/openvinotoolkit/cvat"]},{"cell_type":"markdown","metadata":{"id":"MI-hI8Sf4Mbe"},"source":["- labelimg (라벨 데이터 제작 라이브러리) 설치"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1721705799534,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"UVly2cY74Mbe"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2ovaaHu-4Mbe"},"source":["- labelImg 실행하기"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1721705800023,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"jkQWyEIR4Mbe"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"vsZpYyQC4Mbe"},"source":["<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg1.png\" width=40%></cener>"]},{"cell_type":"markdown","metadata":{"id":"_W8SxFg64Mbe"},"source":["- Open Dir로 사진들이 저장된 디렉토리를 선택\n","  - File List에 선택한 디렉토리에 저장된 파일 목록이 보여짐\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg2.png\" width=40%></center>\n","\n","\n","- File 메뉴에서 PascalVOC 버튼을 클릭(YOLO로 설정됨)하고 라벨링을 수행\n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg3.png\" width=40%></center>\n","\n","- Edit 메뉴에서 create RectBox를 누르고 라벨링 시작\n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg4.png\" width=40%></center>\n","\n","- 마우스를 드래그하여 원하는 모든 대상에 바운딩 박스를 설정하고 라벨값을 입력하고 OK 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg5.png\" width=40%></center>\n","\n","- 이미지의 개체를 모두 라벨링 후에 Save 버튼을 클릭하여 라벨 데이터 저장\n","- 모든 이미지에 대해 라벨링 작업 수행\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg6.png\" width=40%></center>\n","\n","- 해당 폴더에 classes.txt 파일 (라벨명), xxx.txt (라벨명, 바운딩 박스 좌표)이 생성되었는지 확인\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_labelImg7.png\" width=40%></center>"]},{"cell_type":"markdown","metadata":{"id":"mprZt8oh4Mbf"},"source":["- classes.txt 내용"]},{"cell_type":"markdown","metadata":{"id":"4TZieX8Y4Mbf"},"source":["banana<br>\n","apple<br>\n","orange<br>"]},{"cell_type":"markdown","metadata":{"id":"PjcpjuF14Mbf"},"source":["- fruit1.txt 내용 (바운딩 박스 좌표가 0-1 사이값으로 정규화되어 저장)"]},{"cell_type":"markdown","metadata":{"id":"SHRunsTv4Mbf"},"source":["0 0.298843 0.282670 0.502571 0.426136<br>\n","1 0.751285 0.225852 0.317481 0.352273<br>\n","2 0.551414 0.781960 0.318766 0.328125<br>"]},{"cell_type":"markdown","metadata":{"id":"9ivXz4b84Mbf"},"source":["- ./data/images 폴더에 train과 test 폴더를 만들고 이미지를 저장\n","- ./data/images 폴더에 labels 폴더를 만들고 labels 폴더에 train과 test 폴더를 만들고 라벨 데이터를 각각 저장"]},{"cell_type":"markdown","metadata":{"id":"sRTK8L0cmOuE"},"source":["# Roboflow을 이용한 데이터 라벨링\n","\n","- https://roboflow.com 에 접속하고 로그인\n","- workspaece를 생성하고 Create New Project를 클릭하여 새 프로젝트 생성\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow01.png\" width=40%> </center>\n","\n","- 프로젝트 타입, 이름, 검출하고자 하는 대상을 입력하고 Create Public Project 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow02.png\" width=30%> </center>\n","\n","- https://arome1004.cafe24.com/images/cv_project/images/105_dog_cat.zip 를 다운로드하고 압축을 품\n","- Select Files 버튼을 클릭하여 개, 고양이 사진 200장을 선택\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow03.png\" width=30%> </center>\n","\n","- Save and Continue 버튼을 클릭하여 업로드\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow04.png\" width=30%> </center>\n","\n","- Assign Images 버튼을 클릭하여 업로드 완료\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow05.png\" width=20%> </center>"]},{"cell_type":"markdown","metadata":{"id":"sMAE3XyIBDDo"},"source":["- 이미지를 더블클릭하고 라벨링 시작\n","  - 이미지에서 원하는 영역을 선택\n","  - Annotation Editor에 라벨값을 입력하고 Save(Enter) 버큰을 클릭\n","  - 상단의 좌우 버튼을 눌러 이미지 이동\n","  - 라벨링이 완료되면 왼쪽상단의 뒤로가기 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow06.png\" width=40%> </center>\n","\n","  - Add 200 images to Dataset 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow07.png\" width=40%> </center>\n","\n","  - Add Images 버튼을 클릭\n","    - 자동으로 Train, Valid, Test 데이터로 분리\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow08.png\" width=20%> </center>\n","\n","  - Generate 버튼을 클릭하고 Continue 버튼을 클릭하여 전처리 수행 (크기, 뱡향 등)\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow09.png\" width=40%> </center>\n","\n","  - Add Step을 클릭하여 증강 설정 후 Continue 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow10.png\" width=40%> </center>\n","\n","  - Continue 버튼을 클릭 (최대 3배까지 증강)\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow11.png\" width=40%> </center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"b2i9gEzwLH7e"},"source":["- Export Dataset 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow12.png\" width=40%> </center>\n","\n","- Format을 사용할 형식을 설정하고 Continue 버튼을 클릭\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow13.png\" width=30%> </center>\n","\n","- Terminal 탭을 클릭하여 다운로드 명령을 복사하여 코랩에서 실행 (curl 앞에 !를 붙여서 실행)하거나, Raw URL 탭을 클릭하고 URL를 복사하여 데이터셋을 다운로드\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow14.png\" width=30%> </center>\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_roboflow15.png\" width=30%> </center>\n","\n","- 다운받은 파일을 구글 드라이브의 data 폴더에 업로드하여 압축을 푼다\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1721705820003,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"tpp4P3-OQhW5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting roboflow\n","  Downloading roboflow-1.1.36-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: certifi in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (2024.2.2)\n","Requirement already satisfied: chardet==4.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (4.0.0)\n","Collecting idna==3.7 (from roboflow)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (1.4.4)\n","Requirement already satisfied: matplotlib in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (3.8.0)\n","Requirement already satisfied: numpy>=1.18.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (1.26.4)\n","Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n","Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (10.2.0)\n","Requirement already satisfied: python-dateutil in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: python-dotenv in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (0.21.0)\n","Requirement already satisfied: requests in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (2.0.3)\n","Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (4.65.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (6.0.1)\n","Requirement already satisfied: requests-toolbelt in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from roboflow) (1.0.0)\n","Collecting filetype (from roboflow)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (4.25.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests->roboflow) (2.0.4)\n","Downloading roboflow-1.1.36-py3-none-any.whl (76 kB)\n","   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n","   ---------------------------------------- 76.7/76.7 kB 4.2 MB/s eta 0:00:00\n","Downloading idna-3.7-py3-none-any.whl (66 kB)\n","   ---------------------------------------- 0.0/66.8 kB ? eta -:--:--\n","   ---------------------------------------- 66.8/66.8 kB 3.5 MB/s eta 0:00:00\n","Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n","   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n","   --- ------------------------------------ 3.0/38.8 MB 65.2 MB/s eta 0:00:01\n","   ----- ---------------------------------- 5.5/38.8 MB 59.1 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.4/38.8 MB 76.8 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.4/38.8 MB 76.8 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.4/38.8 MB 76.8 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.4/38.8 MB 76.8 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.4/38.8 MB 76.8 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.4/38.8 MB 76.8 MB/s eta 0:00:01\n","   -------- ------------------------------- 8.6/38.8 MB 21.1 MB/s eta 0:00:02\n","   -------------- ------------------------- 14.2/38.8 MB 27.3 MB/s eta 0:00:01\n","   ------------------ --------------------- 17.8/38.8 MB 26.2 MB/s eta 0:00:01\n","   ------------------ --------------------- 17.8/38.8 MB 26.2 MB/s eta 0:00:01\n","   -------------------- ------------------- 20.3/38.8 MB 59.5 MB/s eta 0:00:01\n","   -------------------------- ------------- 25.3/38.8 MB 65.6 MB/s eta 0:00:01\n","   --------------------------- ------------ 26.2/38.8 MB 59.5 MB/s eta 0:00:01\n","   ---------------------------- ----------- 27.5/38.8 MB 43.7 MB/s eta 0:00:01\n","   --------------------------------- ------ 32.6/38.8 MB 59.5 MB/s eta 0:00:01\n","   ---------------------------------------  37.9/38.8 MB 108.8 MB/s eta 0:00:01\n","   ---------------------------------------  38.7/38.8 MB 110.0 MB/s eta 0:00:01\n","   ---------------------------------------  38.7/38.8 MB 110.0 MB/s eta 0:00:01\n","   ---------------------------------------  38.7/38.8 MB 110.0 MB/s eta 0:00:01\n","   ---------------------------------------- 38.8/38.8 MB 43.7 MB/s eta 0:00:00\n","Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Installing collected packages: filetype, opencv-python-headless, idna, roboflow\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.4\n","    Uninstalling idna-3.4:\n","      Successfully uninstalled idna-3.4\n","Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 roboflow-1.1.36\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n","\n","[notice] A new release of pip is available: 24.0 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install roboflow"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":392,"status":"ok","timestamp":1721705823646,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"5DrrJ4AxLfsK"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in Object_detect-1 to yolov7pytorch:: 100%|██████████| 15303/15303 [00:02<00:00, 7405.64it/s] "]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to Object_detect-1 in yolov7pytorch:: 100%|██████████| 612/612 [00:00<00:00, 2264.38it/s]\n"]}],"source":["from roboflow import Roboflow\n","\n","#API KEY\n","rf = Roboflow(api_key=\"uxDMCYPOC6gZcb8lk9Vw\")\n","# WorkSpace name, Project name\n","project = rf.workspace(\"projects-uvuy7\").project(\"object_detect-4bn4p\")\n","# version\n","version = project.version(1)\n","# 사용할 모델\n","dataset = version.download(\"yolov7\")"]},{"cell_type":"markdown","metadata":{"id":"2lEhlNEn8wSo"},"source":["- roboflow의 데이터 세트 다운로드"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1721705828625,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"CDK5vgDJ8tCM"},"outputs":[],"source":["import os.path\n","\n","# yolov7 API를 저장할 폴더 생성하고 yolov7를 clone\n","if not os.path.exists('yolov7'):\n","  !git clone https://github.com/WongKinYiu/yolov7.git"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":347,"status":"ok","timestamp":1721705836070,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"HSpJN_Ym8777"},"outputs":[{"name":"stderr","output_type":"stream","text":["'wget'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n","��ġ ������ �ƴմϴ�.\n"]}],"source":["!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"]},{"cell_type":"markdown","metadata":{"id":"LNT46OIW4Mbg"},"source":["# YoloV7를 이용한 객체 탐지"]},{"cell_type":"markdown","metadata":{"id":"NK2JmIEA4Mbi"},"source":["- YoloV7를 구글 드라이브에 clone하기"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":375,"status":"ok","timestamp":1721705841409,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"LmgtWKP64Mbi","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]}],"source":["!python ./yolov7/train.py --batch 16 --epochs 5 --data ./Object_detect-1/data.yaml --weights \"yolov7_training.pt\""]},{"cell_type":"markdown","metadata":{"id":"KO6nzste-3_m"},"source":["- 훈련된 모델 다운로드"]},{"cell_type":"markdown","metadata":{"id":"DYEDIOkZ4Mbl"},"source":["- 훈련하기\n","\n","  - device : 훈련에 사용할 GPU 번호(ID) - GPU가 하나뿐이므로 0\n","  - data : 데이터 집합 YAML 파일 경로\n","  - img : 사용할 이미지 크기\n","  - cfg : 바로 전에 만든 모델 아키텍처를 로드하는 데 필요한 모델 구성 파일의 경로\n","  - weights : 미리 학습된 모델 경로\n","  - name : 결과를 저장할 runs/train 폴더 내의 폴더명\n","  - hyp : 적절한 YOLOv7-tiny 모델 하이퍼파라미터 파일 경로"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1721705851256,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"mrWdGcMw4Mbl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"sf8eo6Pi4Mbl"},"source":["#### 성능평가\n","\n","- IoU (Intersection over union) : 예측된 바운딩 박스와 사용자가 설정한 바운딩 박스간 중첩되는 부분의 면적을 측정해서 중첩된 면접을 합집합의 면적으로 나눈 것\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_iou.jpg\" width=40%></center>\n","\n","- AP (Average Precision) : 컴퓨터 비전 분야에서 물체 검출 및 이미지 분류 알고리즘의 성능 평가 기준\n","  - AP는 precision-recall 그래프에서 그래프 선 아래쪽의 면적으로 계산\n","  - 보통 계산 전에 PR 곡선을 계단식으로 감소하는 그래프가 되게 하기 위해서 변환하고 넓이를 구함 (적색)\n","  - AP = 왼쪽 큰 사각형의 넓이 + 오른쪽 작은 사각형의 넓이 = 1*0.33 + 0.88*(0.47-0.33) = 0.4532\n","  \n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_ap.png\" width=40%></center>\n","\n","- mAP (Mean Average Precision) : 물체가 여러 개인 경우 각 클래스별로 AP를 구하고 합을 구한 후에 물체의 개수로 나눈 값"]},{"cell_type":"markdown","metadata":{"id":"EnJ2VbOV4Mbl"},"source":["#### 훈련 결과\n","\n","- mAP가 0.5IoU에서 0.738, 0.5:0.95IoU에서 0.411이 나옴\n","\n","<center><img src=\"https://arome1004.cafe24.com/images/cv_project/lecture_image/105_yolov7_train_result.PNG\" width=60%></center>"]},{"cell_type":"markdown","metadata":{"id":"B2JD_n754Mbm"},"source":["- 테스트 데이터 셋에 대해 적용하기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":382,"status":"ok","timestamp":1721705859789,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"tyC-99mVudJM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"YSshqMdZ4Mbm"},"source":["- 테스트 데이터 세트에서 각각 0.798 및 0.454의 mAP로 과소적합 - 데이터 수가 적어서 생기는 문제"]},{"cell_type":"markdown","metadata":{"id":"YgoJVJ7n4Mbo"},"source":["- 테스트 이미지에서 객체 탐지하기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1721705864152,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"ods-D5Dwjl0i"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"582fM0WGkCVN"},"source":["- 결과 출력"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":341,"status":"ok","timestamp":1721705868034,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"b8bWRcTYkD6z"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"44GqLY7olarN"},"source":["- 동영상에서 객체 탐지하기\n","  - inference/images/ 폴더에 영상 업로드"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":364,"status":"ok","timestamp":1721705874558,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"nybQmWfe4Mbo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1721705877628,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"DKnPcvbbpfX4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"A754YcjClhMf"},"source":["- 유튜브 영상에서 객체 탐지하기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1721705881972,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"HtBa8AlK4Mbo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bT4Xla1xllyN"},"source":["- 카메라 영상에서 객체 탐지하기"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":353,"status":"ok","timestamp":1721705885178,"user":{"displayName":"강성관","userId":"00571094306841577419"},"user_tz":-540},"id":"b5xG0ZR74Mbo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"oSdS1G6B4Mbr"},"source":["<table border=1 width=100%>\n","    <tr><td style=\"border: 1px solid black; width:600px; height:40px; text-align: center;\"><font size=4 color=blue><b>정리하기</b></font></td></tr>       \n","    <tr><td style=\"border: 1px solid black; text-align: left;\"><font size=3>\n","        \n","○ 객체 탐지(object detection) : 컴퓨터 비전과 이미지 처리와 관련된 컴퓨터 기술로서, 디지털 이미지와 비디오에서 관심 객체(예: 인간, 건물, 자동차 등)의 위치를 감지하는 작업\n","\n","○ 객체 분류 : 탐지된 객체가 무엇인지 판단하고 분류하는 작업\n","\n","○ 객체 탐지 및 분류 알고리즘\n","\n","  - 머신러닝 기반 접근 : SIFT, HOG 등\n","  \n","  - 딥러닝 기반 접근 : R-CNN, Fast R-CNN, Faster R-CNN, cascade R-CNN, SSD, YOLO, RefineDet 등\n","\n","        \n","○ Two-Stage Detector : Classification, Regional Proposal을 순차적으로 수행하여 결과를 얻는 방법 (정확도는 우수하지만 속도가 느림) - R-CNN, Fast R-CNN, Faster R-CNN 등\n","        \n","○ One-Stage Detector : Classification, Regional Proposal을 동시에 수행하여 결과를 얻는 방법 (속도 개선) - YOLO, SSD, RetinaNet 등\n","\n","        \n","○ 바운딩 박스 (Bounding Box) : 객체 탐지 모델에서 바운딩 박스는 타겟 위치를 특정하기 위해 사용\n","\n","○ Yolo : YoloV1, YoloV2, YoloV3, YoloV4, YoloV5, YoloV7 등           \n","        \n","</font></td></tr>   \n","</table>"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1s3QKfARE8h6RLAj6MAoHX64YtQmc2L5m","timestamp":1721705746936}]},"hide_input":false,"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"280px","left":"57px","top":"111.143px","width":"165px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}
